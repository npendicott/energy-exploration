{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Organized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import os\n",
    "\n",
    "# Plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# RYO\n",
    "from app.ts_decomposition.data.energy_connection import EnergyConnection\n",
    "from app.ts_decomposition.model.series_sample import TimeSeriesSample\n",
    "\n",
    "\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "PROJECT_DATA_DIR = os.path.join(PROJECT_ROOT_DIR, 'data')\n",
    "\n",
    "\n",
    "# Save Images\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\")\n",
    "\n",
    "# File\n",
    "FILE_NAME = \"energydata_complete.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util Funcs\n",
    "def load_data(file_name, data_path=\".\"):\n",
    "    csv_path = os.path.join(data_path, file_name)\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data from Influx\n",
    "*If there are no room readings, it is because I have not worked through that part of the TimeSeriesSample lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "energy_connection = EnergyConnection()\n",
    "\n",
    "# Generate frames from connections\n",
    "sample_frame = energy_connection.sample_series('energy_readings')\n",
    "\n",
    "# TODO: Rooms/QL Extract\n",
    "\n",
    "sample_frame = energy_connection.sample_series('external_readings', append_frame=sample_frame)\n",
    "\n",
    "# Add to object\n",
    "sample = TimeSeriesSample(sample_frame, 'time')\n",
    "\n",
    "sample.base.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# BROKEN\n",
    "#TODO: Broken bc time is now the actual index, need to modify w/o 'key' \n",
    "# Decomp\n",
    "sample.day_of_week_class()\n",
    "sample.weekend_weekday_class()\n",
    "\n",
    "sample.clean_lights()\n",
    "\n",
    "sample.base.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample.train_test_split(20)\n",
    "sample.base.describe()\n",
    "#sample.base_valid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample.base.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ignore = ['sourceid_x', 'sourceid_y']\n",
    "\n",
    "cat = [\n",
    "    'light',\n",
    "    'light_cleaned',\n",
    "    'light_on',\n",
    "    'visibility',\n",
    "    'day_of_week_class',\n",
    "    'weekend_weekday_class'\n",
    "]\n",
    "\n",
    "sample.categorical_features = cat\n",
    "\n",
    "for series in sample.base:\n",
    "\n",
    "    if series not in ignore:\n",
    "        # How to plot on index???\n",
    "        sample.base.plot(kind='line', x=sample.base.index, y=series)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we can observe (read: clean)\n",
    "\n",
    "### Analog Signal ?\n",
    "Appliances: Standard Dev is high compared to mean, especially factoring in min and max. So, we will have a big initial hump (maybe close to localized normal), and some BIG positive outliers\n",
    "\n",
    "Lights: \n",
    "    - a lot of time on 0, maybe we can catogorize/bin this val\n",
    "    - Super stochastic?\n",
    "    - fuzzy => off, low, mid, hi?\n",
    "    \n",
    "### Digital Signal?\n",
    "Visibility: \n",
    "    - one huge bin?\n",
    "    - Split into two \"non 40\" vars, take the hist there?\n",
    "    - Check: three fuzzy blocks?\n",
    "    \n",
    "Windspeed: Levels?\n",
    "\n",
    "Temps:\n",
    "    - \"Spikey bins\"? => Equilibrium point/level?\n",
    "    - otherwise center lump\n",
    "    \n",
    "Humidity:\n",
    "    - left side lump\n",
    "    - but one is flat?\n",
    "    - definitely some cutoff\n",
    "    \n",
    "\n",
    "# TODO: \n",
    "Switch to TS Object from lib\n",
    "Make the influx cutoff from there\n",
    "\n",
    "Two sided structure: \n",
    "    - dataframe for Jupyter Analytics\n",
    "    - Array for implimented ML algorithms\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Go through the series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stationality \n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Autocorr\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Decomps\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "from stldecompose import decompose\n",
    "\n",
    "# ARIMA\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "# Resid\n",
    "from numpy import histogram\n",
    "\n",
    "# Jupyter\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "\n",
    "from pandas import Series\n",
    "from matplotlib import pyplot\n",
    "from numpy import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appliance Energy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "series='appliance'\n",
    "sample.base[series].hist()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample.base.plot(kind='line', x=sample.base.index, y=series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_log = series + '_log'\n",
    "\n",
    "X = sample.base[series].values\n",
    "#series_log = Series(log(X))\n",
    "sample.base[series_log] = log(X)\n",
    "\n",
    "#sample.base[series_log].plot()\n",
    "sample.base[series_log].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample.base.plot(kind='line', x=sample.base.index, y=series_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log gets you something a little more gaussian, I think energy is looking more like a Poisson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stationality\n",
    "\n",
    "https://people.maths.bris.ac.uk/~magpn/Research/LSTS/TOS.html\n",
    "\n",
    "http://denizstij.blogspot.com/2015/01/stationarity-test-with-kpss.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = adfuller(sample.base[series].values)\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Values:')\n",
    "\n",
    "for key, value in result[4].items():\n",
    "    print('\\t%s: %.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sample.stationality(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H(0): Has unit root, is non stationary\n",
    "\n",
    "H(1): No unit root, is stationary\n",
    "\n",
    "p = 0 => Reject (p<0.05)\n",
    "\n",
    "ADF is low, so stationary\n",
    "\n",
    "This would indicate that the series is stationary\n",
    "\n",
    "but p is realllly small, so something may want to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sample.stationality(series_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly lower ADF on the log, but still tiny p, so maybe it really is stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto Corr/Cov\n",
    "https://people.maths.bris.ac.uk/~magpn/Research/LSTS/LACF.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(sample.base[series], lags=500)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_pacf(sample.base[series], lags=500)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like some autocorrelation past 1, possibly more. So, probably some pretty intese autocorrelataion. \n",
    "\n",
    "Is that oscilation something to look into?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal Decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#model = 'additive'\n",
    "model = 'multiplicitive'\n",
    "\n",
    "freq = 144\n",
    "#freq = 1008\n",
    "\n",
    "#result = seasonal_decompose(sample.base[series_log].values, model=model, freq=freq)\n",
    "result = seasonal_decompose(sample.base[series].values, model=model, freq=freq)\n",
    "\n",
    "# Out\n",
    "result.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot residual errors\n",
    "residuals = DataFrame(model_fit.resid)\n",
    "residuals.plot()\n",
    "pyplot.show()\n",
    "residuals.plot(kind='kde')\n",
    "pyplot.show()\n",
    "print(residuals.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "residuals = result.resid[freq:len(result.resid)-freq]\n",
    "plt.hist(residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STL Decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Decompose\n",
    "result = decompose(sample.base[series_log].values, period=freq)\n",
    "\n",
    "# Out\n",
    "result.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = result.resid[freq:len(result.resid)-freq]\n",
    "#hist = histogram(residuals)\n",
    "plt.hist(residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trend:\n",
    "    - range of trend scales roughly inverse to freq\n",
    "    - same for mult v add (because same rolling mean method)\n",
    "    - even at the day level, range is ~20% of observed. So small scale trend\n",
    "    - makes a case for stationary as well\n",
    "Seasonal:\n",
    "    - looks roughly the same shape on multiplicative \n",
    "    - just scaled up\n",
    "    - hard to check for consistency at day level, but month seems ok\n",
    "Residual:\n",
    "    - either a high season, low residual, or low season high residual\n",
    "    - looks different shape though? Not sure what this is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How to calculate R2 w/ moving trend? Or is yhat just the mean, not trend? Should it be of detrend?\n",
    "# R_SQR should be high or low, based on https://people.maths.bris.ac.uk/~magpn/Research/LSTS/TOS.html?\n",
    "result = seasonal_decompose(sample.base[series].values, model=model, two_sided=two_side, freq=period)\n",
    "print(result.resid[period:len(result.resid)-period])\n",
    "\n",
    "ss_res = [(res*res for res in result.resid[period:])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sample.base['time']\n",
    "sample.base.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AR (I) MA\n",
    "\n",
    "https://stats.stackexchange.com/questions/251480/statsmodels-says-arima-is-not-appropriate-because-series-is-not-stationary-how"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    " \n",
    "arima_order = (5,1,0)\n",
    "\n",
    "# fit model\n",
    "X = sample.base[series]\n",
    "\n",
    "X = X.astype('float64')\n",
    "\n",
    "arima = ARIMA(X, order=arima_order)\n",
    "#arima = ARIMA(sample.base[series], order=arima_order)\n",
    "arima_fit = arima.fit(isp=0)\n",
    "print(arima_fit.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "# plot residual errors\n",
    "residuals = DataFrame(arima_fit.resid)\n",
    "residuals.plot()\n",
    "pyplot.show()\n",
    "residuals.plot(kind='kde')\n",
    "pyplot.show()\n",
    "print(residuals.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Tempurature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "series='tempurature'\n",
    "sample.base[series].hist()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample.base.plot(kind='line', x=sample.base.index, y=series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks fairly gaussian, just going to go for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stationality\n",
    "https://people.maths.bris.ac.uk/~magpn/Research/LSTS/TOS.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sample.stationality(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H(0): Has unit root, is non stationary\n",
    "\n",
    "H(1): No unit root, is stationary\n",
    "\n",
    "p = 0 => Reject (p<0.05)\n",
    "\n",
    "ADF is higher, but still stational. Same critical values though, so maybe I am implimenting this method wrong, or something? Temp does look a little less stationary, but no super distinct trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sample.stationality(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly lower ADF on the log, but still tiny p, so maybe it really is stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto Corr/Cov\n",
    "https://people.maths.bris.ac.uk/~magpn/Research/LSTS/LACF.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(sample.base[series], lags=500)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_pacf(sample.base[series], lags=500)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So HIGH autocorr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal Decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "model = 'additive'\n",
    "#model = 'multiplicitive'\n",
    "\n",
    "freq = 144\n",
    "#freq = 1008\n",
    "\n",
    "#result = seasonal_decompose(sample.base[series_log].values, model=model, freq=freq)\n",
    "result = seasonal_decompose(sample.base[series].values, model=model, freq=freq)\n",
    "\n",
    "# Out\n",
    "result.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot residual errors\n",
    "residuals = DataFrame(model_fit.resid)\n",
    "residuals.plot()\n",
    "pyplot.show()\n",
    "residuals.plot(kind='kde')\n",
    "pyplot.show()\n",
    "print(residuals.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "residuals = result.resid[freq:len(result.resid)-freq]\n",
    "#hist = histogram(residuals)\n",
    "plt.hist(residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STL Decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Decompose\n",
    "result = decompose(sample.base[series].values, period=freq)\n",
    "\n",
    "# Out\n",
    "result.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = result.resid[freq:len(result.resid)-freq]\n",
    "#hist = histogram(residuals)\n",
    "plt.hist(residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soooo maybe we need to so some noise reduction or signal identification or something. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How to calculate R2 w/ moving trend? Or is yhat just the mean, not trend? Should it be of detrend?\n",
    "# R_SQR should be high or low, based on https://people.maths.bris.ac.uk/~magpn/Research/LSTS/TOS.html?\n",
    "result = seasonal_decompose(sample.base[series].values, model=model, two_sided=two_side, freq=period)\n",
    "print(result.resid[period:len(result.resid)-period])\n",
    "\n",
    "ss_res = [(res*res for res in result.resid[period:])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AR (I) MA\n",
    "\n",
    "https://stats.stackexchange.com/questions/251480/statsmodels-says-arima-is-not-appropriate-because-series-is-not-stationary-how"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    " \n",
    "arima_order = (5,1,0)\n",
    "\n",
    "# fit model\n",
    "X = sample.base[series]\n",
    "\n",
    "X = X.astype('float64')\n",
    "\n",
    "arima = ARIMA(X, order=arima_order)\n",
    "#arima = ARIMA(sample.base[series], order=arima_order)\n",
    "arima_fit = arima.fit(isp=0)\n",
    "print(arima_fit.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "# plot residual errors\n",
    "residuals = DataFrame(arima_fit.resid)\n",
    "residuals.plot()\n",
    "pyplot.show()\n",
    "residuals.plot(kind='kde')\n",
    "pyplot.show()\n",
    "print(residuals.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light Energy\n",
    "\n",
    "### Seasonal Decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series='light'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "result = seasonal_decompose(sample.base[series].values, model=model, two_sided=two_side, freq=period)\n",
    "\n",
    "# Out\n",
    "result.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STL Decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Decompose\n",
    "result = decompose(sample.base[series].values, period=period)\n",
    "\n",
    "# Out\n",
    "result.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Humidity\n",
    "\n",
    "### Seasonal Decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Decompose\n",
    "result = seasonal_decompose(sample.base['humidity'].values, model=model, two_sided=two_side, freq=period)\n",
    "\n",
    "# Out\n",
    "result.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STL Decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Decompose\n",
    "result = decompose(sample.base['humidity'].values, period=period)\n",
    "\n",
    "# Out\n",
    "result.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationality\n",
    "\n",
    "## DF Test\n",
    "https://machinelearningmastery.com/time-series-data-stationary-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decomp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seasonal Decompose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Decompose\n",
    "result = seasonal_decompose(sample.base['tempurature'].values, model=model, two_sided=two_side, freq=period)\n",
    "\n",
    "# Out\n",
    "result.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dewpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Decompose\n",
    "result = seasonal_decompose(sample.base['tdewpoint'].values, model=model, two_sided=two_side, freq=period)\n",
    "\n",
    "# Out\n",
    "result.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Decompose\n",
    "result = seasonal_decompose(sample.base['pressure'].values, model=model, two_sided=two_side, freq=period)\n",
    "\n",
    "# Out\n",
    "result.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Decompose\n",
    "result = decompose(sample.base['tempurature'].values, period=period)\n",
    "\n",
    "# Out\n",
    "result.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dewpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Decompose\n",
    "result = decompose(sample.base['tdewpoint'].values, period=period)\n",
    "\n",
    "# Out\n",
    "result.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Decompose\n",
    "result = decompose(sample.base['pressure'].values, period=period)\n",
    "\n",
    "# Out\n",
    "result.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "I think most of these trend lines would indicate stationality, i.e. small variations relative to the range.\n",
    "\n",
    "So, it looks like some genral time series approaches may hit some snags. May have to dip into some signal processing to smooth, maybe initially? These \"business level\" \"time series\" may be more meaningful over longer periods, or even just after some noise reduction or smoothing techniques are applie. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it looks like some genral time series approaches may hit some snags. May have to dip into some signal processing to smooth, maybe initially? These \"business level\" \"time series\" may be more meaningful over longer periods, or even just after some noise reduction or smoothing techniques are applie. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
